import websocket import threading import json import time import os import numpy as np import pandas as pd import requests from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor from sklearn.linear_model import Ridge from xgboost import XGBRegressor from lightgbm import LGBMRegressor from catboost import CatBoostRegressor from sklearn.ensemble import StackingRegressor from sklearn.preprocessing import StandardScaler from sklearn.model_selection import train_test_split from sklearn.metrics import mean_absolute_error from keras.models import Sequential from keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional from keras.callbacks import EarlyStopping import joblib # Paramètres Telegram BOT_TOKEN = "7854207959:AAE0Ymz9Iu_EKKJGWSbFe0rLKLFNpuaRU-c" CHAT_ID = "7919382267" def send_telegram_message(text): try: url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage" payload = {"chat_id": CHAT_ID, "text": text} requests.post(url, json=payload) except Exception as e: print("Erreur Telegram:", e) # Paramètres globaux data_buffer = [] window_size = 20 threshold = 2.0 model_update_interval = 180 last_train_time = 0 best_mae = float('inf') error_history = [] history_file = "historique.csv" log_file = "log_predictions.csv" scaler = StandardScaler() # Chargement historique if os.path.exists(history_file): df_hist = pd.read_csv(history_file) historical_data = [{"cote": x} for x in df_hist["cote"].values] else: historical_data = [] # Sauvegarde def save_to_history(cote): historical_data.append({"cote": cote}) if len(historical_data) > 10000: historical_data.pop(0) pd.DataFrame([x["cote"] for x in historical_data], columns=["cote"]).to_csv(history_file, index=False) # Log def log_prediction(real, pred, binaire): with open(log_file, "a") as f: f.write(f"{time.time()},{real},{pred:.4f},{binaire}\n") # Extraction des caractéristiques def extract_features(data): cotes = [item["cote"] for item in data] if len(cotes) >= 5: weights = np.linspace(0.1, 1, len(cotes)) weighted_mean = np.average(cotes, weights=weights) features = [ weighted_mean, np.std(cotes), np.max(cotes), np.min(cotes), np.median(cotes), np.diff(cotes)[-1] if len(cotes) > 1 else 0, sum(x < 1.2 for x in cotes) / len(cotes), sum(cotes[i] > cotes[i-1] for i in range(1, len(cotes))) / len(cotes) ] rsi = 100 - (100 / (1 + (np.mean(np.diff([c for c in cotes if c > 0]))))) sma = np.mean(cotes[-5:]) ema = pd.Series(cotes).ewm(span=5).mean().iloc[-1] upper = sma + 2 * np.std(cotes) lower = sma - 2 * np.std(cotes) features += [rsi, sma, ema, upper, lower] return features return [] # Données pour LSTM def prepare_sequence_data(data): cotes = np.array([item["cote"] for item in data]).reshape(-1, 1) return scaler.fit_transform(cotes).reshape(1, len(data), 1) def create_lstm_model(): model = Sequential() model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=(window_size, 1))) model.add(BatchNormalization()) model.add(LSTM(32)) model.add(Dropout(0.3)) model.add(Dense(1)) model.compile(optimizer='adam', loss='mse') return model # Modèles lstm_model = create_lstm_model() rf_model = RandomForestRegressor(n_estimators=100) xgb_model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.05) lgbm_model = LGBMRegressor(n_estimators=100) catboost_model = CatBoostRegressor(iterations=100, verbose=0) meta_model = GradientBoostingRegressor(n_estimators=100) stacking_model = StackingRegressor(estimators=[ ('rf', rf_model), ('xgb', xgb_model), ('lgbm', lgbm_model), ('cat', catboost_model) ], final_estimator=meta_model) # Entraînement def train_models(): global last_train_time, best_mae X, y = [], [] for i in range(len(historical_data) - window_size): seq = historical_data[i:i + window_size] features = extract_features(seq) if features: X.append(features) y.append(seq[-1]["cote"]) if len(X) < 100: return X = np.array(X) y = np.array(y) X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2) for model in [rf_model, xgb_model, lgbm_model, catboost_model, stacking_model]: model.fit(X_train, y_train) lstm_X = np.array([prepare_sequence_data(historical_data[i:i+window_size])[0] for i in range(len(historical_data)-window_size)]) lstm_y = y lstm_model.fit(lstm_X, lstm_y, epochs=10, batch_size=8, verbose=0, callbacks=[EarlyStopping(patience=3)]) val_preds = np.mean([ rf_model.predict(X_val), xgb_model.predict(X_val), lgbm_model.predict(X_val), catboost_model.predict(X_val), stacking_model.predict(X_val) ], axis=0) mae = mean_absolute_error(y_val, val_preds) if mae < best_mae: best_mae = mae joblib.dump((rf_model, xgb_model, lgbm_model, catboost_model, stacking_model), "best_models.pkl") last_train_time = time.time() # Prédiction def predict(features, sequence_data): try: lstm_input = prepare_sequence_data(sequence_data) lstm_pred = lstm_model.predict(lstm_input)[0][0] rf_pred = rf_model.predict([features])[0] xgb_pred = xgb_model.predict([features])[0] lgbm_pred = lgbm_model.predict([features])[0] cat_pred = catboost_model.predict([features])[0] stack_pred = stacking_model.predict([features])[0] final_pred = np.mean([lstm_pred, rf_pred, xgb_pred, lgbm_pred, cat_pred, stack_pred]) return final_pred except Exception as e: print("Erreur prédiction:", e) return 0 # WebSocket def on_message(ws, message): global data_buffer, error_history try: data = json.loads(message.strip('\x1e')) if data.get("type") == 1 and data.get("target") == "OnCrash": cote = float(data["arguments"]["crash"]) if cote < 1.01 or cote > 100: return save_to_history(cote) data_buffer.append({"cote": cote}) if len(data_buffer) > window_size: data_buffer = data_buffer[-window_size:] features = extract_features(data_buffer) if features: prediction = predict(features, data_buffer) binaire = 1 if prediction > threshold else 0 log_prediction(cote, prediction, binaire) msg = f">>> PRÉDICTION FORTE : cote > {threshold:.2f} ({prediction:.2f})" if binaire else f">>> Prédiction faible : cote <= {threshold:.2f} ({prediction:.2f})" print(msg) send_telegram_message(msg) if binaire: os.system('termux-vibrate -d 300') error_history.append(abs(prediction - cote)) if len(error_history) > 50: error_history.pop(0) if np.mean(error_history) > 0.7: print("Erreur glissante trop élevée. Réentraînement...") threading.Thread(target=train_models).start() if time.time() - last_train_time > model_update_interval: threading.Thread(target=train_models).start() except Exception as e: print("Erreur WebSocket:", e) def on_open(ws): print("Connexion WebSocket établie...") ws.send(json.dumps({"protocol": "json", "version": 1}) + chr(0x1e)) time.sleep(1) ws.send(json.dumps({ "arguments": [{"activity": 30, "account": 1200134785}], "invocationId": "0", "target": "Account", "type": 1 }) + chr(0x1e)) # Lancement ws_url = "wss://l6k-b2jx-c.com/games-frame/sockets/crash?whence=22&fcountry=96&ref=304&gr=2057&appGuid=games-web-app-unknown&lng=fr_FR&access_token=eyJhbGciOiJFUzI1NiIsImtpZCI6IjEiLCJ0eXAiOiJKV1QifQ.eyJzdWIiOiI1MC8xMjAwMTM0Nzg1IiwicGlkIjoiMzA0IiwianRpIjoiMC81ZWMzMzZiMjlkMzJkZWM3OTBjZDY1NzlmMzAzODhlZDljZGJjZTZlNzA0NDg0MmUzMjc0ZmI0YTFlOWQyNDY1IiwiYXBwIjoiN2Q2Y2VmZmVmZDkzYzFiMl8yIiwieHBqIjoiMCIsInhnciI6IjIwNTciLCJuYmYiOjE3NDY3OTY0MjAsImV4cCI6MTc0Njc5NzYyMCwiaWF0IjoxNzQ2Nzk2NDIwfQ.c7ojP6ymN6YDDfROL0ZkXttypjvD0wbTQ78OyW1Iqlg6NWGvPMe1kWCfYqZ5OApEmChFif12bgC84HaCzDBtVw" headers = {"User-Agent": "Mozilla/5.0", "Origin": "https://l6k-b2jx-c.com"} websocket.enableTrace(False) ws = websocket.WebSocketApp(ws_url, header=headers, on_open=on_open, on_message=on_message) threading.Thread(target=ws.run_forever).start()
